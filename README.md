ğŸ§  AI Production Debugging Assistant

An AI-assisted Root Cause Analysis (RCA) system for Kubernetes production incidents.
Built to help SREs and DevOps engineers debug failures faster using structured signal correlation and guarded LLM reasoning.

âš ï¸ This is not a â€œpaste logs into ChatGPTâ€ project.
This system decides what evidence matters first, then allows an LLM to reason only within those constraints.


â“ Why This Project Exists

In real production environments:
Incidents involve multiple weak signals
Logs, events, and restarts are scattered across systems
Engineers manually correlate data under pressure

Naive LLM usage leads to:
hallucinated causes
unverifiable explanations
unsafe conclusions

A plain LLM cannot:
detect an incident window
rank signals by importance
distinguish symptoms from root cause
enforce evidence-based reasoning

This project automates the thinking process of a senior SRE.

ğŸ¯ Design Goals
âœ… Evidence-first, not LLM-first
âœ… Deterministic and auditable RCA
âœ… Kubernetes-native and production-safe
âœ… LLMs are optional, constrained, and replaceable

ğŸ—ï¸ High-Level Architecture
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Kubernetes   â”‚
â”‚ Cluster      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Signal Collectors        â”‚
â”‚ - Pod Events             â”‚
â”‚ - Restart Counts         â”‚
â”‚ - (Metrics / Logs later) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Incident Window          â”‚
â”‚ Detection                â”‚
â”‚ - Time-bounded analysis  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Signal Ranking           â”‚
â”‚ - Type priority          â”‚
â”‚ - Severity               â”‚
â”‚ - Frequency              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prompt Builder           â”‚
â”‚ - Evidence locked        â”‚
â”‚ - Anti-hallucination     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Reasoning Engine     â”‚
â”‚ - JSON-only RCA          â”‚
â”‚ - Confidence score       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ§© Core Features
âœ… Evidence-Based RCA
Uses only observed signals
Explicitly forbids speculation
Every RCA must reference explicit evidence IDs
Responses are rejected if evidence is invalid

âœ… Incident Window Detection
Automatically determines when the incident occurred
Prevents analysis of irrelevant historical noise

âœ… Signal Ranking
Signals are ranked by importance:
Kubernetes events
Pod restarts
Metrics (extensible)
High-impact signals surface first

âœ… LLM Abstraction Layer
Mock LLM for safe local testing
API-based LLMs supported (OpenAI, extensible)
JSON-only output enforced
Schema validation before returning results

âœ… Kubernetes-Native & Production-Safe
Read-only RBAC
Non-root container
Health & readiness probes
Prometheus metrics exposed
Safe rolling deployments

ğŸ“‚ Repository Structure
ai_production_debugger/
â”œâ”€â”€ ai_debugger/
â”‚   â”œâ”€â”€ api/          # FastAPI entrypoint
â”‚   â”œâ”€â”€ collector/   # Kubernetes signal collectors
â”‚   â”œâ”€â”€ correlator/  # Incident window & signal ranking
â”‚   â””â”€â”€ reasoning/   # Prompt templates & LLM clients
â”‚
â”œâ”€â”€ k8s/              # Kubernetes manifests (RBAC, deploy, ingress)
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

â–¶ï¸ Running Locally (Mock Mode)
python -m uvicorn ai_debugger.api.main:app --reload

Health Check
curl http://localhost:8000/health

â–¶ï¸ Example RCA Request
curl -X POST http://localhost:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "llm_mode": "good",
    "signals": [
      {"name": "latency", "value": 1200},
      {"name": "error_rate", "value": 0.18},
      {"name": "cpu", "value": 92}
    ]
  }'

Example Response
{
  "status": "success",
  "mode": "llm",
  "incident": {
    "start": "2026-01-10T16:20:00Z",
    "end": "2026-01-10T16:20:01Z"
  },
  "rca": {
    "root_cause": "high_cpu_usage leading to increased latency and error rate",
    "supporting_evidence_ids": ["E1", "E2", "E3"],
    "confidence": 0.9
  }
}

ğŸ” Why This Is Not a Toy LLM Project
Typical LLM Debugging	        This Project
Free-text reasoning	          Structured JSON only
Hallucinated causes	          Evidence-locked reasoning
No validation	                Strict schema validation
Manual correlation	          Automated signal ranking
Unsafe for prod	              Production-safe by design

ğŸ›£ï¸ Roadmap
 Automatic Prometheus metric ingestion
 Kubernetes events â†’ evidence pipeline
 Multi-LLM fallback strategy

 Confidence-based remediation hooks

 Incident history & RCA persistence
